# 速率限制与配额说明 (Rate Limits & Quotas)

为了保证服务的稳定性和资源的公平分配，**PulseChat API** 对每个账户设置了使用速率限制（Rate Limits）。当请求超过设定的阈值时，系统将返回错误提醒。

---

## 1. 核心指标定义

在 PulseChat 中，我们通过以下三个维度来衡量您的使用量：

| 指标 | 全称 | 说明 |
| :--- | :--- | :--- |
| **RPM** | Requests Per Minute | 每分钟允许发起的最大请求次数。 |
| **TPM** | Tokens Per Minute | 每分钟允许消耗的最大 Token 总数（包含输入和输出）。 |
| **RPD** | Requests Per Day | 每日累计允许发起的最大请求次数。 |

---

## 2. 账户分级限制

您的限制额度取决于您的账户等级。新注册用户默认为 **Free (试用版)** 级别。

| 级别 | 适用对象 | 默认 RPM | 默认 TPM | 备注 |
| :--- | :--- | :--- | :--- | :--- |
| **Free** | 新注册/测试用户 | 3 | 40,000 | 包含 ¥50 体验金 |
| **Standard** | 已充值用户 (累计 < ¥2000) | 60 | 200,000 | 自动激活 |
| **Professional** | 深度合作伙伴 | 200 | 1,000,000 | 需申请 |
| **Enterprise** | 企业级定制客户 | 自定义 | 自定义 | 专享独立集群 |

> ⚠️ **注意：** 不同模型的 TPM 限制是独立计算的。例如，您在 `pulse-v2-pro` 上的高频使用不会直接耗尽 `pulse-v2-light` 的配额。

---

## 3. 模型特定限制 (Context Window)

除速率限制外，每个模型还有其物理上的 **单次对话长度限制**：

* **pulse-v2-pro**: 最大上下文 128,000 Tokens。
* **pulse-v2-light**: 最大上下文 32,000 Tokens。
* **pulse-v2-vision**: 最大上下文 64,000 Tokens。

若请求的消息历史 + 模型生成的回复超过此限制，接口将截断内容或返回错误。

---

## 4. 错误处理与响应

当您的请求触发速率限制时，API 将返回 **HTTP 429 (Too Many Requests)** 状态码。

### 4.1 错误响应示例
```json
{
  "error": {
    "code": "rate_limit_reached",
    "message": "You have reached your RPM limit. Please try again in 15 seconds.",
    "type": "requests",
    "param": null
  }
}
```


### 4.2 响应头信息

在每一个 API 响应头中，我们都会包含当前的限额状态。开发者可以通过解析这些 HTTP Header 字段，在代码中实现精准的流量控制与实时监控：

| Header 字段 | 类型 | 含义 |
| :--- | :--- | :--- |
| `x-ratelimit-limit-requests` | Integer | 账户当前配置的每分钟请求数 (RPM) 上限 |
| `x-ratelimit-remaining-requests` | Integer | 当前时间窗口（本分钟）内剩余的可请求次数 |
| `x-ratelimit-reset-requests` | String | 计数器重置所需的剩余时间（格式通常为秒，如 `15s`） |

---


## 5. 开发者最佳实践

为了避免您的业务因触发速率限制而中断，并提升用户体验，我们强烈建议采取以下技术手段：

### 5.1 指数退避策略 (Exponential Backoff)
当您的应用程序接收到 `HTTP 429 (Too Many Requests)` 错误时，**严禁立即重试**。
* **机制**：在重试之前引入延迟，且延迟时间随重试次数呈指数增长。
* **建议步长**：建议初始等待 1秒，后续按照 2秒、4秒、8秒... 的序列增加，直至请求成功。



### 5.2 流式输出 (Stream)
对于对话类应用，建议在请求参数中设置 `"stream": true`。
* **优势**：虽然流式传输不改变 Token 总消耗数（TPM），但它允许模型在生成过程中实时向客户端推送数据。
* **效果**：显著降低**首屏感知延迟 (Time to First Token)**，让用户感觉响应更加迅速。

### 5.3 Prompt 优化
更短的 Prompt 不仅能节省成本，还能有效规避 TPM 限制。
* **精简系统提示词**：移除冗余的规则说明。
* **管理上下文历史**：避免将完整的历史记录全部发送，建议仅保留最近的 5-10 轮对话，或使用摘要技术压缩历史。

### 5.4 本地缓存 (Caching)
对于高频、固定答案的问题（如产品介绍、FAQ），建议在您的应用层增加缓存机制。
* **实现**：使用 Redis 或本地数据库存储已生成的回复。
* **收益**：既能节省 API 调用额度，又能实现毫秒级的瞬间响应。

---


## 6. 提升额度 (Quota Increase)

如果您现有的配额无法满足生产环境或大规模业务需求，可以通过以下两种方式获取更高的限制额度：

### 6.1 自助提升 (Automatic Upgrade)
* **操作方式**：通过 **[PulseChat 控制台]** 充值余额。
* **生效规则**：当账户累计充值或消费达到指定阈值，账户等级将自动从 **Free** 升级至 **Standard**，实时生效并提升 RPM/TPM 限额。

### 6.2 人工申请 (Manual Application)
若您的业务场景属于深度合作、高并发生产环境或企业级定制，需要超越标准配额的限制：
1.  **控制台申请**：进入 **[控制台] -> [配额管理]**，提交在线申请单，并说明您的业务场景及预估用量。
2.  **邮件联系**：直接发送邮件至 [sales@dolphinstudio.com](mailto:sales@dolphinstudio.com)，我们的商务团队将在 1-3 个工作日内完成审核与配置。

---

**海豚工作室 (Dolphin Studio)** 致力于提供稳定、高效、可扩展的算力支持。

> **版权所有** > © 2024 - 2026 PulseChat. All Rights Reserved.